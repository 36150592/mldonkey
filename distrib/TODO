TODO list for client
====================

set_locale(LC_NUMERIC, "C");

Program received signal SIGSEGV, Segmentation fault.
0x0818884e in MD4Transform ()
(gdb) bt
#0  0x0818884e in MD4Transform ()
#1  0x00000000 in ?? ()
Cannot access memory at address 0x384b8bcf

- if you cancel one file, all sources that have only this file should be
immidiately deleted
- if you restart the donkey, the new sources queue is full of sources
from the last session of MLdonkey and all of them have to be asked until
any new sources that are send from servers or by source propagation can
be asked. I think the new sources should be asked first and the old
sources should only be asked when they have rare files

I would like a state between DOWNLOADING and PAUSED that does not
query for the file anymore but still accepts blocks for it and
utilised queue positions.

c) High memory usage is still not fixed. For the first 2-3 hours MLDonkey
runs very well (using 15-10 MB of memory). Then suddenly it begins to
eat memory very quickly (+ 1 MB every 10 seconds). This way MLDonkey
slows down my machine (64 MB of RAM) and I have to kill it. The
similar experience with 2.02-4 but this version comsumes all my memory
after 10 minutes of running. So 2-3 hours of running is a nice
improvement in 2.02-5 :-) I'm running Debian 3.0 Woody.

BTW, I am downloading only one but very popular file.

--
on version 2.02-5 when I do a recover_temp, on a list of 19 files now I have
only 1... what's going on???

Also, the downloads option on the html doesn't work... I know that there is
a patch somewhere on the list but how I can apply that... maybe anyone could
fix the cvs no?

o be more precise: After shutting down, the bytes are correctly written
to the files.ini, but after a start, they are treated in an incorrect
manner, causing the unfinished chunks to be lost.

You can see this, if you copy the files.ini to a safe place and do a
"diff -u" right after mldonkey starts.

ascii: [(197)(144)(197)(217) 6(255) C(204)(226) a o(234) 6 T(28)(140) % ;]
dec:
[(197)(144)(197)(217)(54)(255)(67)(204)(226)(97)(111)(234)(54)(84)(28)(140)(37)(59)]
Received unknown UDP packet
ascii: [(197)(144)(213) 7(195)(211)(232)(6) ](8)(207) ~ ( #(29)(20)(148)(180)]
dec:
[(197)(144)(213)(55)(195)(211)(232)(6)(93)(8)(207)(126)(40)(35)(29)(20)(148)(180)]
Received unknown UDP packet
ascii: [(197)(144)(197)(217) 6(255) C(204)(226) a o(234) 6 T(28)(140) % ;]
dec:
[(197)(144)(197)(217)(54)(255)(67)(204)(226)(97)(111)(234)(54)(84)(28)(140)(37)(59)]
Received unknown UDP packet
ascii: [(197)(144)(197)(217) 6(255) C(204)(226) a o(234) 6 T(28)(140) % ;]
dec:
[(197)(144)(197)(217)(54)(255)(67)(204)(226)(97)(111)(234)(54)(84)(28)(140)(37)(59)]
Received unknown UDP packet
ascii: [(197)(144)(197)(217) 6(255) C(204)(226) a o(234) 6 T(28)(140) % ;]
dec:
[(197)(144)(197)(217)(54)(255)(67)(204)(226)(97)(111)(234)(54)(84)(28)(140)(37)(59)]
Received unknown UDP packet


******************


Bugs in unstable-2-02-3:
 * Remove the mp3info Not_Found error
 * Installer...
 * prevent duplicates in sources_for
 * add an option for overnet access
 * add an option for locale (or verify that LANG is set correctly LANG=C ??)
 * keep connecting to bad sources with earlier times if we are not using
    all the connection slots...
 * Stop connecting to sources when download bandwidth is fully used.
 * Change the color of tabs when things change
 * Different black lists for clients and servers ?
 * Fix stats with sources, remove servers
 * Send a news update 2.02
 * Remove sources of cancelled files
 * Verify that file sizes are always used as positive integers

donkey/:
 * New source management
 * MLdonkey client generate "Exceeding Block Boundaries" errors which lose
     bandwidth
 * Extended search doesnot work after connect because no ping was sent.
 * Query and parse WEB server pages such as jiggle
 * Option to clear the server list at restart or when a new list is received
 * Cancel and Redownload doesnot work
 * What happens when a shared file cannot be read ?
 * Downloaded files seem not shared

direct_connect/:
 * When a download is finished, can the link be reused ?
 * Don't always download from incoming peer the files list
 * Reply to search requests

gui/:
 * Popup when clicking on a file with stats on sources
 * Show list of file names for files being downloaded
 * Add preview for downloaded files

soulseek/:
 * Test new rooms
 * Display the number of new message per room

common/:
 * Common functions for linear uploads and downloads

limewire/:
 * Chech the is_http_ok function: too wide ?

net/:
 * Socks 5 support
 * Better bandwidth control: take TCP-IP packet header size into account
    and UDP too.

opennap/:
 * Register files on server
 * Reply to upload requests

- to be inserted a line of 
above GMain.Main.init ().
*********

For 2.1:
  - What about having one result per file ?
  - Allow upload at least in Direct Connect... Maybe in gnutella too, even
     if it is probably a waste of bandwidth. Upload should probably be
     concentrated on eDonkey2000, where it is better used. However, if we
     don't want to be kicked from other network, it is better to allow them
     to download from us. Maybe we could use priorities, but how ? Each network
     would have a score, and the better score would be given bandwidth first ?
   - Incomplete files can be automatically deleted when too old (7 days)
   - Add a "cp" function to change the temp directory without breaking
       the sparse file format (ie without increasing the size of copied files)

and more:

   - Objects should be stored in Weak hash tables everywhere, except when they
      are roots (servers, downloaded files, searches).
   - Event list: the current mechanism for notifications to GUIs is
      inefficient: a slow GUI prevents other GUIs from receiving fast
      updates and requires lots of CPU. A better system would be
      to have an event fifo: Each event is stored and kept in the FIFO.
      When a GUI connects, it points to the beginning of the fifo.
      Then, events are sent to it, and he can go ahead in the fifo.
      When an event is obsolete, it is replaced in place by the new state.
      The new state indicates its new position in the fifo. When events are
      sent to the GUI, they must be at the indicated position in the fifo.
   - Client side verification of query results

*********

Later:
  * Plugins.
  * Correct display of availability.
  * Popup
  * Keep (server_ip, server_port, id) for indirect connections.
  * Manager of shared files/directories.
  * Add Friends in console and WEB. 
  * Allow hostname instead of IPs in servers and friends.
  * Queue uploads per chunk.
  * Add prefered servers.
  * Save options in a modular way (each server in a file ?).
  * Recommandation for upload.
  * Download priorities (what does it mean ?).
  * Use source groups for local downloads.
  * Use a cache of data to help diffusing files.
  * Check that program exists before trying to execute.
  * Clean the clients_by_num table from clients which are not useful anymore.
  * remove locations of downloaded files.
  * check that 'cancelled' files cannot be shared also in incoming/
  * don't add sources to files already downloaded.
  * efficient management of buffers
  * background searches: 
   - search and automatically download files
 + remove unused sources (cleanly remove them at least once per hour)
 + commit page to select saved name
 + Imported files should have permission 644.[ Bug #420 ]
 
TODO list for server
====================
* Send a ping to all clients every minute
* Implement the whole protocol for TCP clients
* Implement the whole protocol for UDP clients
* Implement the protocol for UDP servers
* Implement indexation
* Implement localisation

KNOWN COMMENTS (from savannah and forum):
========================================
Browser: Mozilla/4.75 [en] (X11; U; Linux 2.4.17 i686; Nav) On the help page, it still says you can't set uploads
under 1K. 
If a server IP along with a colon seperated port number
is specified in the Server IP box, and enter hit, then
it gets added. This would make copy/paste from a list
of servers lots easier. Saving upstats would be nice, as well as some way of
resetting it, to get a better idea of which files to
keep shared. The downloads panel is a little busy, and not good for
small screens (some people still have to use 640x480) Perhaps move the 'save files' to an incoming tab?
(which can flash when it's got files in) On the same lines, why not show the filename/details
(the one above the colour bar) in a line, with name in
one box, size in the next (perhaps with bytes/Mb
added), and the format in another, with the colour bar
as the last item in the line, taking up the whole width
of the client, with the 'connections' panel only
popping up over the right-hand-side of the screen when
a filename is double-clicked (or when show connections
is picked from the menu)
The MD4 recover might move to the incoming tab, and the
ed2k file to below the filename/colourbar line, and
automatically change when a new file is clicked,
to show the ed2k: link.
Maybe the cancel/retry-connect could move to the
connections panel? On the search results tab, it would be nice to indicate
number of results per file, to give at least an
indication of availability.



Since Pierre asked for discussions on big changes in mldonkey, I think
it is time to really discuss source management.

We have different constraints:
1) trying too many sources takes a lot of bandwidth, and a lot of memory
2) keeping the number of sources low takes a lot of CPU, and can
  prevent from finding good sources.

Thus, it would be interesting to find a good compromise.

My current ideas: four level of sources for each file

* Normal sources: these sources have been tested recently, and they
   have chunks interesting for us. They take a big structure in
   memory, and they are limited by the max_sources_per_file option.
   We connect to them every 10 minutes to ask for a slot.

* Emerging sources: these sources have just been announced. they could
   have something interesting for us. We never connected to them.
   They are stored in a compressed form (only IP + port).

* Concurrent sources: these sources have the file, but not the chunks
  we want. They can be tested from time to time to see if they have
  new chunks. One chunk is 9MB, at 5 KB/s, it is half an hour to
  download.  Depending on the number of chunks they had the last time,
  we should not try them before at least 1 hour.

* Old sources: these sources have once been indicated as sources for
   the file. We couldn't connect to them to verify that, or at least,
   we could'nt connect to them for a long period. We should test them
   anyway, maybe once every 6 hours ?  They are removed after the
   max_sources_age delay.

When new slots are available in the normal sources, they are filled
from the other kind of sources, mainly by taking emerging sources,
then concurrent sources and finally old sources. After 1 to 5 failed
attempts to connect, they are moved to the old sources.

The first kind of sources would take a lot of memory (at least 300
bytes), whereas the other sources only take around 30 bytes. If we
keep all the sources that way, 10000 sources would take:
300 normal sources = 90 kB
10000 other sources = 300 kB
--> 400 kB per very popular file.

MLdonkey would keep asking for sources until at least
good_sources_threshold of its normal sources slots are used.

What do you think of such a scheme ?

- MLDonkey

PS: some computations.

300 normal sources = 300 connections/10 minutes = 1 connection/2 seconds
  for 30 files, it is 15 connections/second

1 connection =
  TCP Connection = 80 bytes upload, 40 bytes download
  edonkey hand check ~ 200 bytes upload, 200  bytes download
    ~ 300 B up, 300 B down
30 files --> 15x300 = 4.5 kB/s up and down

If we move to old sources after 1 failed attempt = 10 minutes,
 we can test 300 sources/10 minutes, so 10000 old sources/5 hours
2 failed attempts = 10 hours
3 failed attempts = 15 hours
4 failed attempts = 20 hours
5 failed attempts = 25 hours


******************************************************************

How it should work:

For each file, we have:    

    ...

    mutable file_sources : client Intmap.t; 
    
    mutable file_emerging_sources : source Fifo.t;
    mutable file_concurrent_sources : source Fifo.t;
    mutable file_old_sources : source Intmap.t;

}

and source = {
    source_addr : Ip.t * int;
    mutable source_client: client_kind; 
  }

and client_kind = 
  SourceClient of client
| SourceRecord of float (* last connection attempt *)
  
When we receive a new source from anywhere:
- Never seen it: add it to 'file_emerging_sources'
- Already seen:
     * If in concurrent_sources: do nothing
     * If in normal_sources: do nothing
     * If in emerging_sources: do nothing
     * If in old_sources: move it to emerging_sources

The options:
*  max_clients_per_second

Constraints:
* Check all clients every 10 minutes = 600 seconds
    max_all_sources = 600 * max_clients_per_second

What we have:
* a set of files with current sources.

How should it work ????

At the beginning, when mldonkey starts, all the sources are emerging.

Every second, we call the function "check_sources".


NEW SOURCE MANAGEMENT:
----------------------

Just a thought, lol. Also, how about making an mldonkey version that can run as a deomon just like giFT? 

A few more ideas:

GUI IDEAS: 
- Add a columb to the download window that will say YES as soon as 100% of the file is found on the network (for say a period of 2 days?) 
- Add the option to rename file while it's downloading (allowing to choise from list of common filenames for that file). 
- Any way to add a way to display the queue position on overnet and emule clients? (yes, they support that feature) 
- Posibly an improved search.. 

GENERAL: 
- Posibility to set mldonkey to folow symbolic links to a certain depth. 
- Prioritizing download/uploads (has been discussed a lot, so I thought I'll mention it here) 
- Automatic upload regulation to increase upload when download is slow (not sure how that works for that edonkeybot had it and it worked quite nicely) 
- What ever happened to the 'collection' files from edonkey? I would like mldonkey to have that feature, so people can share collections of entire series. 

WEB INTERFACE: 
- I would prefer the filesize in webinterface to be displayed in mbytes rather then bytes, same with comulitive upload/download speed at bottom right corner of gui. 
- Display free disk space in Web Interface so that you can check remotely how much space you still have, (good if you access mldonkey with remote windows). 
- Any chance of adding a graph to the web interface to show download/upload for a set period of time? that would truley rock. 
- Please add number of sources and number of connected sources to web interface.[/b]
